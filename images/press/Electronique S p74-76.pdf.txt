# Nourrir l’intelligence artificielle en robotique avec les données des capteurs
## La nouvelle génération de robots industriels s’appuie sur la synergie entre les données des capteurs et l’intelligence artificielle exécutée à la périphérie. Encore faut-il bien comprendre comment tirer le meilleur parti de ces capteurs...
> Electronique S1 Sep 2019

![EAI](EAI.png)

Des systèmes industriels classiques aux tout derniers robots collaboratifs, ou « cobots », les robots se nourrissent du nombre croissant de données extrêmement variées générées par les capteurs. Ces données améliorent les modèles d’apprentissage automatique et d’intelligence artificielle (IA) qui rendent les robots « autonomes », capables de prendre des décisions en temps réel et de se mouvoir dans des environnements dynamiques. Les robots industriels sont généralement confinés dans des « cages » ; si un individu pénètre dans cet environnement, ils sont automatiquement mis à l’arrêt pour des raisons de sécurité. Mais en limitant la collaboration entre humains et robots, on se prive de nombreux avantages. Doter ces derniers de fonctions autonomes permettrait une cohabitation sûre et productive avec les humains.

Les fonctions de détection et de perception intelligente sont cruciales sur les applications robotiques. En effet, l’efficacité de ces systèmes – et en particulier des systèmes d’apprentissage automatique et d’IA – dépend largement des performances des capteurs, qui leur fournissent des données essentielles. La grande variété de capteurs actuellement sur le marché, de plus en plus sophistiqués et précis et associés à des systèmes capables d’agréger l’ensemble des données qu’ils génèrent, ne cesse d’améliorer les capacités de perception et de reconnaissance des robots.

Le développement de l’IA

L’automatisation des robots révolutionne le secteur de la production depuis quelque temps déjà; mais l’intégration de l’IA est vouée à renforcer cette tendance au cours des prochaines années. Selon une étude de MarketsandMarkets, le marché des technologies d’automatisation des robots passera d’environ 270 millions de dollars en 2016 à près de 4,9 milliards en 2023. L’Institute for High Performance de la société de conseil Accenture a étudié l’impact de l’IA dans douze économies développées. Il a conclu qu’elle pourrait doubler leur croissance annuelle d’ici à 2035, améliorer la productivité de 40% et transformer la nature du travail en créant une nouvelle relation hybride entre l’homme et la machine – favorisant ainsi la créativité, l’innovation et la croissance en collaboration avec des robots dotés d’IA.

L’apprentissage automatique se fait en deux temps, la phase d’entraînement et la phase d’inférence, qui peuvent être effectuées sur deux plateformes de traitement complètement distinctes. La partie entraînement se fait généralement hors ligne, sur des ordinateurs de bureau, ou dans le cloud. Elle consiste à alimenter un réseau de neurones artificiels avec de vastes ensembles de données. Pendant cette phase, les performances en temps réel et la puissance ne constituent pas un enjeu. On obtient un système d’IA entraîné qui, une fois déployé, sera capable d’assurer une tâche donnée  inspecter une bouteille sur une chaîne de production, compter les personnes présentes dans une pièce et suivre leurs mouvements, ou encore déterminer si un billet est faux.

Mais pour que l’IA tienne ses promesses, dans de nombreux secteurs, la fusion des données des capteurs (qui a lieu pendant la phase d’inférence, qui exécute l’algorithme d’apprentissage automatique entraîné) doit s’effectuer en temps réel – ou peu s’en faut. Les concepteurs doivent donc déplacer l’apprentissage automatique et les modèles d’apprentissage approfondi vers la périphérie, et déployer l’exécution de l’inférence au sein d’un système intégré.

Par exemple, les cobots sont conçus pour travailler en étroite collaboration avec les humains. Ils utilisent les données fournies par les capteurs de proximité et de vision afin de ne pas les mettre en danger, tout en les assistant dans des activités difficiles pour eux. Toutes ces données doivent être traitées en temps réel. Or, le cloud n’est pas capable de garantir la vitesse et la faible latence nécessaires. Afin de surmonter cet obstacle, les systèmes d’IA de pointe sont déplacés vers la périphérie – ce qui, dans le cas des cobots, implique qu’ils soient embarqués.

Un modèle d’IA décentralisé

Ce modèle décentralisé repose sur des processeurs fortement intégrés, dotés - d’un riche ensemble de périphériques qui assurent l’interface avec divers capteurs; - de fonctions de traitement ultra-performantes afin d’exécuter des algorithmes de vision par ordinateur; - de la capacité d’accélérer les opérations d’inférence d’apprentissage approfondi. Toutes ces fonctions doivent fonctionner efficacement, avec relativement peu d’énergie et dans un format suffisamment compact pour être accueillies par les périphériques. À mesure que l’apprentissage automatique se popularise, on voit apparaître de plus en plus de moteurs d’inférence optimisés en termes de consommation et de taille. Il s’agit de matériel spécialisé, dédié spécifiquement aux opérations d’inférence. Dans un environnement intégré, le choix d’un système sur puce (SoC) est souvent pertinent. En plus de compter diverses unités de traitement capables d’exécuter les opérations d’inférence d’apprentissage approfondi, un SoC est doté de plusieurs composants nécessaires pour couvrir la totalité de l’application intégrée. Certains incluent des fonctions graphiques, d’affichage, d’accélération vidéo et de réseau industriel – pour des solutions monopuce qui font davantage qu’exécuter des opérations d’apprentissage automatique et d’IA. Les processeurs Sitara AM57x constituent un bon exemple de processeurs capables d’exécuter les fonctions d’IA en périphérie. Ils disposent de plusieurs périphériques haute vitesse qui assurent l’interface avec divers capteurs – vidéo, temps de vol (ToF), détection et estimation de la distance par laser (lidars) ou encore à ondes millimétriques (mmWave)– ainsi que de coeurs C66x dédiés au traitement du signal numérique et de sous-systèmes de moteur de vision intégrés pour exécuter les algorithmes d’IA et les opérations d’inférence d’apprentissage approfondi.

Cobots

Généralement, on ne peut s’approcher sans risque des robots industriels en fonctionnement. Mais les cobots, avec leurs mouvements lents et gracieux, sont conçus pour fonctionner côte à côte avec les humains.

Selon la norme ISO TS 15066, un robot collaboratif est un robot qui peut être utilisé pour des opérations collaboratives, c’està-dire dans lesquelles humains et robots travaillent ensemble, dans un espace défini, à des tâches de production (sont exclus de cette définition les systèmes robot + robot ainsi que les sites sur lesquels humains et robots travaillent à des moments distincts). Ils sont paramétrés et déployés de manière à prévoir les collisions potentielles entre les éléments physiques des robots (ou ses extensions virtuelles, telles que les lasers) et leurs opérateurs. Le recours à des capteurs qui déterminent la position et la vitesse exactes des opérateurs est d’autant plus important. Les constructeurs de cobots sont tenus de doter leurs systèmes de capteurs environnementaux et de fonctions de redondance de haut niveau, afin de détecter et de prévenir rapidement toute collision potentielle. Des capteurs intégrés, reliés à une unité de contrôle, détecteront un risque de collision entre un bras robotisé et un humain ou un objet quelconque, et l’unité de contrôle désactivera immédiatement le robot. Même chose en cas de défaillance de l’un des capteurs ou du montage électronique. À mesure que les cobots s’adapteront à des environnements industriels exigeants, les fabricants les intégreront de plus en plus sur leurs sites – en particulier s’ils ont des objectifs de retour sur investissement stricts ou souhaitent accélérer leurs cycles de production.

Robots logistiques

Les robots logistiques sont des unités mobiles utilisées dans des environnements susceptibles d’être fréquentés par des humains, tels que les entrepôts, les plateformes logistiques, les ports et les campus. Ils récupèrent les marchandises pour les amener sur les stations de conditionnement, ou bien les transportent d’un bâtiment à l’autre sur le site d’une entreprise. Certains sont également capables de les emballer directement. Généralement, ces robots se déplacent dans un environnement donné. Ils ont besoin de capteurs pour se localiser, cartographier leur environnement, mais aussi pour éviter les collisions (en particulier avec les humains). Jusqu’à récemment, la plupart des robots logistiques suivaient des itinéraires prédéfinis. Désormais, ils sont capables d’adapter leur navigation en fonction de l’emplacement des autres robots, des humains et des cartons grâce à des technologies de détection à ultrasons, infrarouges et lidars. Dans la mesure où le robot se déplace, l’unité de contrôle est située à l’intérieur, et souvent en communication sans fil avec un système de contrôle central à distance. Aujourd’hui, les robots logistiques adoptent des technologies de pointe, telles que des logiques d’apprentissage automatique et des systèmes de collaboration humain-machine et d’analyse de l’environnement. L’augmentation des coûts du travail et les réglementations gouvernementales strictes contribuent à l’engouement pour les robots logistiques. Leur popularité tient également à une réduction du coût de l’équipement, des composants tels que les capteurs, et de l’intégration (ainsi que du temps nécessaire pour la réaliser). Le marché mondial des robots logistiques devrait afficher un taux de croissance annuel moyen supérieur à 28% entre 2018 et 2022 d’après une étude de Technavio.

Robots de livraison

Dans le périple d’un produit depuis les étagères de l’entrepôt jusqu’au domicile du client, le « dernier kilomètre » désigne la dernière étape, lors de laquelle le paquet arrive devant la porte de l’acheteur. Outre qu’elle joue un rôle essentiel dans la satisfaction du client, cette phase est coûteuse et prend du temps. Les coûts de livraison de proximité représentent une part substantielle des frais de port 53% au total. Ce « dernier kilomètre » est donc devenu le point de mire du développement et de la mise en oeuvre de nouvelles technologies robotiques capables d’améliorer les processus et d’augmenter leur efficacité.

Capteurs optiques basés sur le temps de vol (ToF)

Ces capteurs s’appuient sur le principe de mesure de la distance à partir du temps de vol. Ils utilisent pour cela un éclairage actif à une ou plusieurs photodiodes. Les ondes réfléchies par les obstacles sont comparées à l’onde transmise afin de déterminer le retard de phase, qui est corrélée à la distance à mesurer. Ces données permettent ensuite de créer une représentation 3D de l’objet détecté. Les capteurs ToF sur puce tels que ceux de TI assurent des fonctions de détection basées sur le temps de vol, plus performantes que celles des détecteurs de proximité, pour des systèmes de vision nouvelle génération. Leur intégration sur une puce offre toute latitude pour personnaliser la conception des applications de vision robotique ou autres, à l’aide de différents outils, notamment un module d’évaluation et un kit de développement de caméra hautement configurable qui fournit les coordonnées 3D de chaque pixel pour une carte de profondeur précise, ce qui facilite la personnalisation du développement. Les solutions discrètes tirent parti des topologies de réseau de pointes et des technologies de semi-conducteurs, tels que les convertisseurs numériques de temps et le nitrure de gallium (GaN). Grâce à un capteur ToF 3D tel que l’OPT8320 de TI, les robots sont capables de déterminer l’angle exact d’une vis, et d’ajuster celui du tournevis pour garantir un alignement de vissage parfait sans intervention humaine. Un dispositif d’entrée analogique basé sur la technologie ToF tel que l’OPT3101 détermine la distance entre un bras robotique et un objet cible, améliorant ainsi la précision de positionnement. Pour améliorer la résolution de la détection 3D, les systèmes de lumière structurée flexibles reposant sur la technologie DLP peuvent permettre d’atteindre une précision de l’ordre du micromètre, voire davantage.

Capteurs de température et d’humidité

De nombreux robots ont besoin de mesurer la température, et parfois l’humidité de leur environnement et de leurs composants (notamment les moteurs et les cartes mères principales dédiées à l’IA) afin de vérifier qu’ils fonctionnent dans des conditions sûres. C’est particulièrement important pour ce type de dispositifs, car lorsqu’un moteur fonctionne en charge élevée, il peut consommer beaucoup d’énergie et chauffer. Une surveillance précise de la température protège les moteurs, et permet de les pousser davantage avant d’atteindre leurs marges de sécurité. De plus, tous les autres capteurs étant sensibles à la température, ils profitent de la compensation thermique. Si l’on connaît la température, on peut corriger la dérive des autres capteurs pour obtenir des mesures plus précises. Dans les zones équatoriales et tropicales, les capteurs de température et d’humidité sont également utilisés pour prévoir le point de rosée, et ainsi assurer la protection et la maintenance prédictive des systèmes électroniques.

Capteurs à ultrasons

Les capteurs optiques sont susceptibles de ne pas fonctionner si le robot est aveuglé par une lumière vive ou circule dans un environnement très sombre. Les capteurs à ultrasons se soustraient à ces limitations en émettant des ondes ultrasonores et en détectant les échos renvoyés par les objets, à la manière des chauvessouris. Ils fonctionnent ainsi quelle que soit la luminosité. La détection par ultrasons est une alternative aux radars plus lente, mais moins coûteuse pour les robots qui ne nécessitent pas d’atteindre de hautes vitesses. Ce type de capteurs est également plus fiable que les capteurs ToF pour éviter les obstacles, car ils ne sont pas affectés par la quantité de lumière ambiante réfléchie par les obstacles. Dans la mesure où ils utilisent les ondes sonores et non la lumière, ils sont capables de détecter du verre ou d’autres surfaces transparentes.

Capteurs de vibrations

Les capteurs de vibrations industriels constituent un élément essentiel de la surveillance de l’état du matériel et s’avèrent nécessaires à la maintenance préventive. Les plus courants dans ce type d’environnements sont les capteurs piézoélectriques intégrés. Grâce aux capteurs de vibrations, les robots sont capables de déterminer si certaines de leurs pièces mécaniques sont endommagées ou usées, ce qui facilite les actions de maintenance préventive et évite la mise en danger des opérateurs. Le recours à l’IA et à l’apprentissage automatique peut améliorer grandement la précision de ces prévisions.

Capteurs mmWave

Les capteurs mmWave utilisent les ondes radio et leurs échos pour déterminer la direction et la distance d’un objet en mouvement, en mesurant trois valeurs  la vitesse, l’angle et l’intervalle. Les robots sont ainsi capables de mieux prévoir leurs actions en fonction de la vitesse des objets qui approchent du capteur. Les capteurs radars offrent d’excellentes performances dans des conditions de faible luminosité et peuvent assurer leurs fonctions de détection à travers des matériaux tels que le plâtre, le plastique et le verre. Les radars mmWave à structure Cmos garantissent des mesures extrêmement précises, non seulement de la distance des objets présents dans le champ de vision, mais également de la vitesse relative des obstacles. Les capteurs mmWave monopuces sont compacts, légers, et permettent que les opérations de traitement en temps réel soient réalisées au sein des périphériques, éliminant souvent la nécessité d’ajouter des processeurs. Grâce à la technologie des ondes millimétriques, il est possible de concevoir des appareils trois fois moins volumineux et deux fois moins lourds que des télémètres à lidars miniatures. On limite ainsi le coût des composants, la taille du capteur, et les millions d’instructions par seconde que le processeur de commande centrale doit émettre par rapport à un système de vision par ordinateur. Montés directement dans des boîtiers en plastique sans lentille externe, ouverture ou surface de détection, ces capteurs sont extrêmement résistants, et respectent l’indice de protection 69K. Les premiers capteurs mmWave étaient coûteux et volumineux, et nécessitaient des composants discrets. Désormais, grâce à l’intégration de fonctions radiofréquences, de ressources de traitement et de mémoire sur une puce monolithique Cmos, on peut raisonnablement affirmer que les capteurs mmWave compléteront, voire remplaceront les technologies de détection actuellement utilisées sur les systèmes robotiques dans les prochaines années. Des systèmes de détection radar plus avancés peuvent assurer des fonctions d’odométrie très précises grâce à une unité de mesure inertielle, parfois associée à un GPS. Les capteurs mmWave fournissent des informations odométriques supplémentaires aux robots qui circulent sur des terrains accidentés ou dont le châssis est sujet à d’importants mouvements de tangage et de lacet ; pour cela, ils émettent des signaux chirp en direction du sol et mesurent l’effet Doppler du signal de retour. 

Sur les systèmes robotiques intelligents, adaptatifs, dotés d’une fonction d’apprentissage autonome, la chaîne de transmission des signaux nécessite une fusion en temps réel des données générées par les capteurs. Ceux d’un cobot sont, d’une certaine façon, semblables aux cinq sens humains. Or, tous nos sens sont essentiels pour fonctionner en parfaite autonomie. Chacun utilise différentes zones de notre cerveau, et une part plus ou moins importante de ses capacités de traitement. Ainsi, la vue le sollicite davantage que l’ouïe ou l’odorat. De la même manière, les robots intégreront davantage de capteurs connectés à des systèmes d’IA et d’apprentissage automatique internes, le principal défi pour les constructeurs étant la nécessité de faire fonctionner et communiquer plusieurs systèmes d’IA pour former un système d’apprentissage automatique alimenté par les données des capteurs hybrides. Les concepteurs de robots comptent sur les circuits intégrés de pointe pour éviter les complications liées à la conception et à la certification des montages, et ainsi accélérer le développement de produits qu’ils pourront proposer rapidement à leurs clients du secteur industriel. 

Pour améliorer les robots industriels, ces circuits intégrés assurent des fonctions de détection précise, de conversion ultrarapide des signaux, et de calcultraitement accéléré des signaux afin de garantir une réponse en temps réel et des communications à haute vitesse. Associés à des semiconducteurs avancés, tels que les transistors à effet de champ au nitrure de gallium, ils permettent également une alimentation hautement efficace et compacte. Les nouveaux circuits intégrés accompagnent également de nouveaux standards dans le secteur, tels que les câbles Ethernet à paire torsadée unique et l’alimentation via ce type de câbles, qui simplifient le câblage et renforcent la fiabilité des systèmes.